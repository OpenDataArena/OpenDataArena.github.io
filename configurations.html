<!DOCTYPE html>
<html lang="zh-CN">
    <head>
        <meta charset="UTF-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <title>Configurations - Training and Testing Settings</title>
        <link rel="stylesheet" href="./css/style.css" />
        <link rel="stylesheet" href="./css/dropdown-styles.css" />
        <link rel="stylesheet" href="./css/mobile.css" />
        <link
            href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css"
            rel="stylesheet"
        />
        <!-- Google tag (gtag.js) -->
        <script
            async
            src="https://www.googletagmanager.com/gtag/js?id=G-36SWWSWBC7"
        ></script>
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag() {
                dataLayer.push(arguments);
            }
            gtag("js", new Date());
            gtag("config", "G-36SWWSWBC7");
        </script>
        <style>
            body {
                font-family: -apple-system, BlinkMacSystemFont, "Segoe UI",
                    Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji",
                    "Segoe UI Emoji", "Segoe UI Symbol";
                margin: 0;
                padding: 0;
                background-color: #f4f7f6;
                color: #333;
            }
            .rules-container {
                max-width: 1200px;
                margin: 20px auto;
                padding: 20px;
                background-color: #fff;
                box-shadow: 0 0 15px rgba(0, 0, 0, 0.1);
                border-radius: 8px;
            }
            .rules-header {
                text-align: center;
                margin-bottom: 30px;
                padding-bottom: 20px;
                border-bottom: 2px solid #e0e0e0;
            }
            .rules-header h1 {
                color: #1039a2;
                font-size: 2.2em;
                margin-bottom: 10px;
            }
            .rules-header .back-link {
                display: inline-block;
                margin-top: 15px;
                padding: 10px 20px;
                background-color: #1039a2;
                color: white;
                text-decoration: none;
                border-radius: 5px;
                font-size: 1em;
                transition: background-color 0.3s ease;
            }
            .rules-header .back-link:hover {
                background-color: #0d2c7a;
            }
            .rules-header .back-link i {
                margin-right: 8px;
            }
            .rules-section {
                margin-bottom: 40px;
            }
            .rules-section h2 {
                font-size: 1.8em;
                color: #333;
                margin-top: 30px;
                margin-bottom: 20px;
                border-bottom: 1px solid #eee;
                padding-bottom: 10px;
            }
            .rules-section h2 i {
                margin-right: 10px;
                color: #1039a2;
            }
            .rules-section p {
                font-size: 1.1em;
                margin-bottom: 15px;
                line-height: 1.6;
            }
            .rules-table {
                width: 100%;
                border-collapse: collapse;
                margin-bottom: 20px;
                font-size: 0.95em;
                table-layout: auto;
            }
            .rules-table th,
            .rules-table td {
                border: 1px solid #ddd;
                padding: 12px;
                text-align: left;
                vertical-align: top;
                word-wrap: break-word;
            }
            .rules-table th {
                background-color: #f7f9fa;
                font-weight: 600;
                color: #333;
            }
            .dataset-cell {
                white-space: pre-wrap;
                word-break: break-word;
                line-height: 1.5;
            }
            .footer-nav {
                text-align: center;
                margin-top: 40px;
                padding-top: 20px;
                border-top: 1px solid #eee;
            }
            .rules-table-shot td:nth-child(5),
            .rules-table-shot th:nth-child(5) {
                width: 70px;
                min-width: 70px;
                max-width: 70px;
            }
        </style>
    </head>
    <body>
        <!-- Header -->
        <header class="header">
            <div class="title-container nav-left">
                <div class="nav-title-group">
                    <h1 class="nav-main-title">
                        <a href="index.html" class="nav-home-link"
                            >OpenDataArena</a
                        >
                    </h1>
                    <div class="nav-slogan">
                        Benchmark Data Value - Right at Your Fingertips
                    </div>
                </div>
            </div>
            <nav class="nav-right">
                <ul class="nav-list">
                    <li class="nav-item">
                        <a
                            href="leaderboard.html"
                            >Leaderboard</a
                        >
                    </li>
                    <li class="nav-item">
                        <a
                            href="data-comparison.html?id=2"
                            >Data Comparison</a
                        >
                    </li>
                    <li class="nav-item">
                        <a
                            href="configurations.html"
                            >Configurations</a
                        >
                    </li>
                    <li class="nav-item">
                        <a
                            href="contribution.html"
                            >Contribution</a
                        >
                    </li>
                    <li class="nav-item">
                        <a
                            href="tools.html"
                            >Tools</a
                        >
                    </li>
                </ul>
            </nav>
        </header>
        <!-- 悬浮操作菜单 -->
        <div class="fab-menu">
            <div class="fab-actions">
                <div class="fab-action fab-back">
                    <a href="index.html" class="fab-icon" title="Back to Home"
                        ><i class="fas fa-arrow-left"></i
                    ></a>
                    <a
                        href="index.html"
                        class="fab-label-btn"
                        title="Back to Home"
                        ><i class="fas fa-arrow-left"></i
                        ><span>Back to Home</span></a
                    >
                </div>
                <div class="fab-action fab-feedback">
                    <button
                        class="fab-icon"
                        title="Feedback"
                        onclick="openFeedbackForm()"
                    >
                        <i class="fas fa-comment"></i>
                    </button>
                    <button
                        class="fab-label-btn"
                        title="Feedback"
                        onclick="openFeedbackForm()"
                    >
                        <i class="fas fa-comment"></i><span>Feedback</span>
                    </button>
                </div>
            </div>
            <button class="fab-main" title="More actions">
                <i class="fas fa-ellipsis-h"></i>
            </button>
        </div>

        <div class="rules-container">
            <section class="rules-section">
                <h2><i class="fas fa-cogs"></i>Training Settings</h2>
                <p>
                    <strong>Framework:</strong>
                    <a
                        href="https://github.com/hiyouga/LLaMA-Factory/tree/v0.9.2"
                        target="_blank"
                        class="repo-link"
                        ><u>LLaMA_Factory version 0.9.2</u></a
                    >
                </p>
                <p><strong>Base Model:</strong> Llama-3.1-8B, Qwen2.5-7B</p>
                <h3
                    style="
                        color: #1039a2;
                        font-size: 1.3em;
                        margin-top: 25px;
                        margin-bottom: 15px;
                    "
                >
                    <i class="fas fa-sliders-h" style="margin-right: 8px"></i
                    >Parameter Details
                </h3>
                <ul
                    style="
                        font-size: 1.1em;
                        line-height: 1.6;
                        margin-left: 20px;
                        margin-bottom: 20px;
                    "
                >
                    <li>
                        To ensure fair training and minimize the impact of
                        training configurations on evaluation results, we
                        carefully reference a wide range of existing literature
                        to standardize the hyperparameter settings across
                        different models. This approach helps eliminate
                        performance bias caused by inconsistent training setups.
                    </li>
                    <li>
                        - The final training configurations for the LLaMA and
                        Qwen model families are summarized below.
                    </li>
                </ul>
                <table class="rules-table">
                    <thead>
                        <tr>
                            <th></th>
                            <th>LLaMA</th>
                            <th>Llama for long CoT</th>
                            <th>Qwen</th>
                            <th>Qwen for long CoT</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>GPU</td>
                            <td>8*A100</td>
                            <td>8*A100</td>
                            <td>8*A100</td>
                            <td>8*A100</td>
                        </tr>
                        <tr>
                            <td>Base model</td>
                            <td>Meta-Llama-3.1-8B</td>
                            <td>Meta-Llama-3.1-8B</td>
                            <td>Qwen2.5-7B</td>
                            <td>Qwen2.5-7B</td>
                        </tr>
                        <tr>
                            <td>deepspeed</td>
                            <td>ds_z2_config</td>
                            <td>ds_z2_config</td>
                            <td>ds_z2_config</td>
                            <td>ds_z2_config</td>
                        </tr>
                        <tr>
                            <td>template</td>
                            <td>default</td>
                            <td>default</td>
                            <td>default</td>
                            <td>default</td>
                        </tr>
                        <tr>
                            <td>cutoff_len</td>
                            <td>4096</td>
                            <td>32768</td>
                            <td>4096</td>
                            <td>32768</td>
                        </tr>
                        <tr>
                            <td>preprocessing_num_workers</td>
                            <td>16</td>
                            <td>16</td>
                            <td>true</td>
                            <td>true</td>
                        </tr>
                        <tr>
                            <td>Packing</td>
                            <td>false</td>
                            <td>true</td>
                            <td>false</td>
                            <td>true</td>
                        </tr>
                        <tr>
                            <td>per_device_train_batch_size</td>
                            <td>4</td>
                            <td>1</td>
                            <td>4</td>
                            <td>1</td>
                        </tr>
                        <tr>
                            <td>per_device_train_batch_size</td>
                            <td>4</td>
                            <td>2</td>
                            <td>4</td>
                            <td>2</td>
                        </tr>
                        <tr>
                            <td>learning_rate</td>
                            <td>2.0e-5</td>
                            <td>3.0e-5</td>
                            <td>5.0e-6</td>
                            <td>5.0e-5</td>
                        </tr>
                        <tr>
                            <td>use_liger_kernel</td>
                            <td>true</td>
                            <td>true</td>
                            <td>true</td>
                            <td>true</td>
                        </tr>
                        <tr>
                            <td>num_train_epochs</td>
                            <td>3.0</td>
                            <td>3.0</td>
                            <td>3.0</td>
                            <td>3.0</td>
                        </tr>
                        <tr>
                            <td>lr_scheduler_type</td>
                            <td>cosine</td>
                            <td>cosine</td>
                            <td>cosine</td>
                            <td>cosine</td>
                        </tr>
                        <tr>
                            <td>warmup_ratio</td>
                            <td>0.03</td>
                            <td>0.03</td>
                            <td>0.1</td>
                            <td>0.1</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <section class="rules-section">
                <h2><i class="fas fa-vial"></i>Testing Settings</h2>
                <p>
                    <strong>Framework:</strong>
                    <a
                        href="https://github.com/opencompass-ai/opencompass/tree/v0.4.2"
                        target="_blank"
                        class="repo-link"
                        ><u>OpenCompass version 0.4.2</u></a
                    >
                </p>
                <h3
                    style="
                        color: #1039a2;
                        font-size: 1.3em;
                        margin-top: 25px;
                        margin-bottom: 15px;
                    "
                >
                    <i class="fas fa-sliders-h" style="margin-right: 8px"></i
                    >Parameter Details
                </h3>
                <table class="rules-table">
                    <thead>
                        <tr>
                            <th></th>
                            <th>LLaMA</th>
                            <th>Qwen</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>max-out-len</td>
                            <td>32768</td>
                            <td>32768</td>
                        </tr>
                        <tr>
                            <td>hf-type</td>
                            <td>chat</td>
                            <td>chat</td>
                        </tr>
                        <tr>
                            <td>inference setting</td>
                            <td>vllm_llama3_1_8b_instruct</td>
                            <td>vllm_qwen2_5_7b_instruct</td>
                        </tr>
                        <tr>
                            <td>accelerator</td>
                            <td>vllm+cutoff</td>
                            <td>vllm+cutoff</td>
                        </tr>
                    </tbody>
                </table>
                <ul
                    style="
                        font-size: 1.1em;
                        line-height: 1.6;
                        margin-left: 20px;
                        margin-bottom: 20px;
                    "
                >
                    <li>
                        To achieve reliable and fair comparisons of model
                        performance, we design a standardized and reproducible
                        evaluation pipeline based on extensive preliminary
                        experiments and analysis. Key aspects include:
                    </li>
                    <ul style="line-height: 1.6; margin-left: 40px">
                        <li>
                            Evaluation strictly follows official protocols or
                            widely adopted tools in the community, such as
                            <a
                                href="https://github.com/openai/math-eval-harness"
                                target="_blank"
                                class="repo-link"
                                ><code><u>math-eval-harness</u></code></a
                            >
                            and
                            <a
                                href="https://github.com/EleutherAI/lm-evaluation-harness"
                                target="_blank"
                                class="repo-link"
                                ><code><u>lm-evaluation-harness</u></code></a
                            >, to ensure consistency and comparability with
                            existing benchmarks.
                        </li>
                        <li>
                            To mitigate potential performance bias caused by
                            inaccurate answer extraction, we employ
                            high-performance models to assist in
                            post-processing:
                        </li>
                        <ul
                            style="
                                line-height: 1.6;
                                margin-left: 60px;
                                margin-bottom: 20px;
                            "
                        >
                            <li>
                                For <strong>code-related benchmarks</strong>, we
                                adopt the default evaluation logic provided by
                                the original tools.
                            </li>
                            <li>
                                For <strong>non-code benchmarks</strong>, we use
                                powerful large models (e.g.,
                                <a
                                    href="https://github.com/IAAR-Shanghai/xVerify"
                                    target="_blank"
                                    class="repo-link"
                                    ><code><u>xVerify</u></code></a
                                >,
                                <a
                                    href="https://github.com/KbsdJames/Omni-Judge"
                                    target="_blank"
                                    class="repo-link"
                                    ><code><u>Omni-Judge</u></code></a
                                >) to extract and evaluate answers, ensuring
                                higher accuracy and robustness in the results.
                            </li>
                        </ul>
                    </ul>
                    <li>
                        The detailed evaluation configurations used in our
                        testing tools are listed below.
                    </li>
                </ul>
                <table class="rules-table rules-table-shot">
                    <thead>
                        <tr>
                            <th>Domain</th>
                            <th>Benchmarks</th>
                            <th>Benchmark_file</th>
                            <th>Evaluator</th>
                            <th>Shot</th>
                            <th>Metric</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>general</td>
                            <td>DROP</td>
                            <td>drop_gen_a2697c</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>3shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>general</td>
                            <td>IFEval</td>
                            <td>IFEval_gen</td>
                            <td>IFEvaluator</td>
                            <td>0shot</td>
                            <td>Average accuracy on all IFEval benchmarks</td>
                        </tr>
                        <tr>
                            <td>general</td>
                            <td>AGIEval</td>
                            <td>agieval_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>general</td>
                            <td>MMLU-PRO</td>
                            <td>mmlu_pro_few_shot_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>5shot</td>
                            <td>Average accuracy on all mmlu pro benchmarks</td>
                        </tr>
                        <tr>
                            <td>math</td>
                            <td>Omni-MATH</td>
                            <td>omni_math_gen</td>
                            <td>KbsdJames/Omni-Judge</td>
                            <td>0shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>math</td>
                            <td>OlympiadBenchMath</td>
                            <td>OlympiadBenchMath_0shot_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>math</td>
                            <td>GSM8K</td>
                            <td>gsm8k_0shot_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>math</td>
                            <td>MATH-500</td>
                            <td>math_prm800k_500_0shot_cot_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>math</td>
                            <td>AIME_2024</td>
                            <td>aime2024_repeat8_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>Average accuracy of 8 run</td>
                        </tr>
                        <tr>
                            <td>code</td>
                            <td>HumanEval</td>
                            <td>humaneval_gen_8e312c</td>
                            <td>HumanEvalEvaluator</td>
                            <td>0shot</td>
                            <td>pass@1</td>
                        </tr>
                        <tr>
                            <td>code</td>
                            <td>HumanEval+</td>
                            <td>humaneval_plus_gen_8e312c</td>
                            <td>HumanEvalPlusEvaluator</td>
                            <td>0shot</td>
                            <td>pass@1</td>
                        </tr>
                        <tr>
                            <td>code</td>
                            <td>MBPP</td>
                            <td>sanitized_mbpp_mdblock_gen_a447ff</td>
                            <td>MBPPEvaluator</td>
                            <td>3 shot</td>
                            <td>pass@1</td>
                        </tr>
                        <tr>
                            <td>code</td>
                            <td>LiveCodeBench</td>
                            <td>livecodebench_gen</td>
                            <td>LCBCodeGenerationEvaluator</td>
                            <td>0shot</td>
                            <td>pass@1</td>
                        </tr>
                        <tr>
                            <td>reasoning</td>
                            <td>ARC_c</td>
                            <td>ARC_c_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>reasoning</td>
                            <td>BBH</td>
                            <td>bbh_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>accuracy</td>
                        </tr>
                        <tr>
                            <td>reasoning</td>
                            <td>KOR-Bench</td>
                            <td>korbench_single_0_shot_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0shot</td>
                            <td>Average accuracy on all korbench benchmarks</td>
                        </tr>
                        <tr>
                            <td>reasoning</td>
                            <td>CaLM</td>
                            <td>calm</td>
                            <td>CaLMEvaluator</td>
                            <td>0shot</td>
                            <td>Average accuracy on all calm benchmarks</td>
                        </tr>
                        <tr>
                            <td>reasoning</td>
                            <td>GPQA</td>
                            <td>gpqa_xver_gen</td>
                            <td>IAAR-Shanghai/xVerify-9B-C</td>
                            <td>0 shot</td>
                            <td>accuracy</td>
                        </tr>
                    </tbody>
                </table>
                <ul
                    style="
                        font-size: 1.1em;
                        line-height: 1.6;
                        margin-left: 20px;
                        margin-bottom: 20px;
                    "
                >
                    <li>
                        The complete evaluation setup and parameter
                        configurations can be found at:
                        <a
                            href="https://github.com/OpenDataArena/OpenDataArena-Tool"
                            target="_blank"
                            class="url"
                            >https://github.com/OpenDataArena/OpenDataArena-Tool</a
                        >
                    </li>
                </ul>
            </section>
            <section class="rules-section">
                <h2><i class="fas fa-database"></i>Dataset Selection Rules</h2>
                <p>
                    To ensure fairness and effectiveness in evaluation, we have
                    established strict dataset selection criteria. All datasets
                    used for training and evaluation are sourced from the
                    Hugging Face platform and must meet the following screening
                    conditions:
                </p>

                <h3
                    style="
                        color: #1039a2;
                        font-size: 1.3em;
                        margin-top: 25px;
                        margin-bottom: 15px;
                    "
                >
                    <i class="fas fa-filter" style="margin-right: 8px"></i
                    >Selection Criteria
                </h3>

                <table class="rules-table">
                    <thead>
                        <tr>
                            <th style="width: 25%">Criteria</th>
                            <th style="width: 75%">Requirements</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Impact Metrics</strong></td>
                            <td>
                                <code>likes</code> or
                                <code>downloads</code> count greater than
                                <strong>10</strong> on Hugging Face platform,
                                ensuring community recognition
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Priority Ranking</strong></td>
                            <td>
                                In domains with abundant training data (e.g.,
                                general dialogue, mathematical reasoning, code
                                generation), prioritize datasets with higher
                                <code>likes</code> counts
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Recency Requirement</strong></td>
                            <td>
                                Dataset last updated after
                                <strong>January 2023</strong>, ensuring data
                                timeliness and relevance
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Size Limitation</strong></td>
                            <td>
                                Dataset size limited to
                                <strong>under 1M</strong>, balancing training
                                effectiveness with computational resource
                                consumption
                            </td>
                        </tr>
                        <tr>
                            <td><strong>Suitability Assessment</strong></td>
                            <td>
                                Dataset purpose or content must be suitable for
                                <strong>SFT (Supervised Fine-Tuning)</strong>
                                training, containing high-quality
                                instruction-response pairs
                            </td>
                        </tr>
                    </tbody>
                </table>

                <h3
                    style="
                        color: #1039a2;
                        font-size: 1.3em;
                        margin-top: 25px;
                        margin-bottom: 15px;
                    "
                >
                    <i class="fas fa-check-circle" style="margin-right: 8px"></i
                    >Quality Assurance
                </h3>

                <p>
                    To ensure training data quality, we conduct the following
                    additional validations:
                </p>
                <ul
                    style="
                        font-size: 1.1em;
                        line-height: 1.6;
                        margin-left: 20px;
                    "
                >
                    <li>
                        <strong>Content Review:</strong> Check datasets for
                        harmful, biased, or inappropriate content
                    </li>
                    <li>
                        <strong>Format Standardization:</strong> Ensure all
                        datasets conform to unified input-output format
                        requirements
                    </li>
                    <li>
                        <strong>Diversity Balance:</strong> Maintain diversity
                        and balance across different domains
                    </li>
                    <li>
                        <strong>Regular Updates:</strong> Periodically update
                        selections based on community feedback and newly
                        released high-quality datasets
                    </li>
                </ul>
            </section>
        </div>

        <footer>
            <div class="footer-content">
                <div class="footer-links">
                    <h4>Related Links</h4>
                    <div class="links-container">
                        <a
                            href="https://opendatalab.github.io"
                            target="_blank"
                            rel="noopener noreferrer"
                        >
                            <i class="fas fa-globe"></i>
                            OpenDataLab Research
                        </a>
                        <a
                            href="https://opendatalab.org.cn"
                            target="_blank"
                            rel="noopener noreferrer"
                        >
                            <i class="fas fa-home"></i>
                            OpenDataLab
                        </a>
                        <a
                            href="https://github.com/OpenDataArena/OpenDataArena-Tool"
                            class="github-repo-link"
                            target="_blank"
                            rel="noopener noreferrer"
                        >
                            <i class="fab fa-github"></i>
                            GitHub Repository
                        </a>
                        <a
                            href="mailto:opendataarena@163.com"
                            class="contact-link"
                        >
                            <i class="fas fa-envelope"></i>
                            Contact Us
                        </a>
                    </div>
                </div>
                <div class="footer-copyright">
                    <p>&copy; 2025 OpenDataArena. All rights reserved.</p>
                </div>
            </div>
        </footer>
        <script>
            function openFeedbackForm() {
                const googleFormUrl =
                    "https://docs.google.com/forms/d/e/1FAIpQLSe2Mh4L3e-1TvlCl-Qfl_WasFk2dPO2mFcbmfMG4iF9IgKuIQ/viewform?usp=dialog";
                try {
                    const newWindow = window.open(
                        googleFormUrl,
                        "_blank",
                        "width=800,height=600,scrollbars=yes,resizable=yes"
                    );
                    if (
                        !newWindow ||
                        newWindow.closed ||
                        typeof newWindow.closed === "undefined"
                    ) {
                        window.location.href = googleFormUrl;
                    }
                } catch (error) {
                    window.location.href = googleFormUrl;
                }
            }
        </script>
    </body>
</html>
